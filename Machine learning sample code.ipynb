{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip, ujson, requests, urllib2, wget, re, dill\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn import cross_validation, grid_search\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV, ElasticNet, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import collections\n",
    "\n",
    "#Download data\n",
    "#the url for this dataset is purposefully omitted\n",
    "url = '...'\n",
    "filename = wget.download(url)\n",
    "\n",
    "#read the zip file\n",
    "with gzip.open('yelp_train_academic_dataset_business.json.gz', 'r') as f:\n",
    "    file_content = f.read()\n",
    "    \n",
    "#save as json file\n",
    "with open('yelp_academic_dataset_business.json', 'w') as f:\n",
    "    f.write(file_content)\n",
    "with open('yelp_academic_dataset_business.json', 'r') as f:\n",
    "    data = f.readlines()\n",
    "    \n",
    "#read in as list of dictionaries\n",
    "keys = ['name','full_address','city','state','latitude', 'longitude','categories','attributes','stars']\n",
    "list_dict = []\n",
    "for entry in data:\n",
    "    item = ujson.loads(entry)\n",
    "    list_dict.append({key: item[key] for key in keys})\n",
    "\n",
    "#convert to pandas dataframe\n",
    "df=pd.DataFrame(list_dict)\n",
    "df.loc[:,'full_address'] = df.full_address.str.replace('\\n',' ')\n",
    "\n",
    "#read into pandas with columns of interest\n",
    "keys = ['name','full_address','city','state','latitude', 'longitude','categories','attributes','stars']\n",
    "list_dict = []\n",
    "for entry in data:\n",
    "    item = ujson.loads(entry)\n",
    "    list_dict.append({key: item[key] for key in keys})\n",
    "    \n",
    "#to pandas    \n",
    "df=pd.DataFrame(list_dict)\n",
    "#clean up the addresses\n",
    "df.loc[:,'full_address'] = df.full_address.str.replace('\\n',' ')\n",
    "#clean up the city names\n",
    "df.loc[:,'city'] = df.city.map(lambda x: \" \".join([a.strip() for a in x.split()]) )\n",
    "#target\n",
    "y=df['stars']\n",
    "\n",
    "\n",
    "#City Model\n",
    "class city_model(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # select the city column and combine with the target column\n",
    "        self.df = pd.concat([X[self.key],y],1)     \n",
    "        # calculate mean for each city\n",
    "        self.dfmean = self.df.groupby(self.key).mean().reset_index() \n",
    "        # make a dictionary\n",
    "        self.dic = self.dfmean.set_index('city')['stars'].to_dict() \n",
    "        # calculate the mean of all cities\n",
    "        self.mean = self.df.stars.mean() \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if type(X)==dict:\n",
    "            city = str(X[self.key])\n",
    "            # if the city is in dictionary, look it up\n",
    "            # if the city is not in the dictionary, assign the average score\n",
    "            if city in self.df.city.tolist(): \n",
    "                self.result = self.dic[city]\n",
    "            else:\n",
    "                self.result = self.mean  \n",
    "        else:\n",
    "            self.result = self.df['city'].map(lambda x: self.dic[x])\n",
    "                \n",
    "        return self.result\n",
    "\n",
    "#initialize, fit and save model to \"city_model\"\n",
    "citymodel = city_model('city')\n",
    "citymodel.fit(df, y)\n",
    "citymodel.predict(test)\n",
    "dill.dump(citymodel, open('city_model','w'))\n",
    "\n",
    "\n",
    "#lat_long_model\n",
    "class ColumnSelectTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        # initialization code\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # fit the transformation\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if type(X)==dict:\n",
    "            self.li=[]\n",
    "            # for json, build a list of lists (n_sample x n_feature)\n",
    "            # for pandas format, output n_sample x n_feature array\n",
    "            for k in self.key:\n",
    "                self.li.append(X[k])                  \n",
    "            self.df = [self.li]             \n",
    "        else:\n",
    "            self.df = X[self.key].as_matrix()         \n",
    "        return self.df \n",
    "    \n",
    "class ll_model(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #GridsearchCV\n",
    "        param_grid = { \"n_estimators\": range(10, 50, 20), \"min_samples_leaf\": range(30,100,20) }    \n",
    "        self.random_forest_cv = grid_search.GridSearchCV(RandomForestRegressor(warm_start=True), \n",
    "                                                       param_grid=param_grid, \n",
    "                                                       scoring='mean_squared_error')\n",
    "        self.random_forest_cv.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.tmp = self.random_forest_cv.predict(X)\n",
    "        # if one by one array returned for one input, get the number\n",
    "        # if a larger array returned, use the array form\n",
    "        if len(self.tmp) ==1:\n",
    "            self.result = self.tmp[0]   \n",
    "        else:\n",
    "            self.result = self.tmp      \n",
    "        return self.result\n",
    "\n",
    "latln_model = Pipeline([('trans', ColumnSelectTransformer(['latitude','longitude'])),\n",
    "                        ('est', ll_model())\n",
    "                      ])\n",
    "\n",
    "#fit and save the model\n",
    "latln_model.fit(df, y)\n",
    "dill.dump(latln_model, open('latln_model','w'))\n",
    "\n",
    "\n",
    "\n",
    "#Category model\n",
    "class CategoryTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        # initialization with key\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "  \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # transform the data\n",
    "        # for json format\n",
    "        # build a list of dictionaries with value 1 for present categories\n",
    "        if type(X)==dict:\n",
    "            self.XX={}\n",
    "            for item in self.categories:\n",
    "                if item in X[self.key]:\n",
    "                    self.XX.update({item: 1})   \n",
    "                else:\n",
    "                    self.XX.update({item: 0})   \n",
    "        else:\n",
    "            # Training using pandas dataframe\n",
    "            # construct a list of all categories from training dataset\n",
    "            self.list_of_lists = X[self.key].tolist()\n",
    "            self.categories = list(set([item for sublist in self.list_of_lists for item in sublist]))\n",
    "\n",
    "            # transform the data from pandas dataframe to list of dictionaries\n",
    "            self.XX = X[self.key].map(lambda x: {item: 1 for item in x}).tolist() \n",
    "        \n",
    "        return self.XX # transformation\n",
    "\n",
    "class lr_model(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        cv = cross_validation.KFold(5)\n",
    "        ratios = [.1,.2,.3,.5,.9]\n",
    "        \n",
    "        self.linear_regression_cv = ElasticNetCV(n_alphas=5, l1_ratio=ratios, cv=cv, n_jobs = -1)\n",
    "        self.linear_regression_cv.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.tmp = self.linear_regression_cv.predict(X)\n",
    "        if len(self.tmp) ==1:\n",
    "            self.result = self.tmp[0]       \n",
    "        else:\n",
    "            self.result = self.tmp          \n",
    "\n",
    "        return self.result\n",
    "    \n",
    "cate_model = Pipeline([('trans', CategoryTransformer('categories')),\n",
    "                       ('vect', DictVectorizer()),\n",
    "                       ('TF-IDF', TfidfTransformer()),         # adding the TF-IDF\n",
    "                       ('est', lr_model())\n",
    "                      ])\n",
    "\n",
    "#fit and save the model\n",
    "cate_model.fit(df,y)\n",
    "dill.dump(cate_model, open('cate_model','w'))\n",
    "\n",
    "\n",
    "#Attribute model\n",
    "class AttributeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        # initialization with key ('attributes')\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def flattern(self, d, parent_key=\"\", sep=\"_\"):\n",
    "        flat_dict = []\n",
    "        for k, v in d.items():\n",
    "            new_key = parent_key + sep + k if parent_key else k\n",
    "            if type(v)==dict:\n",
    "                flat_dict.extend(self.flattern(v, new_key, \"_\"))\n",
    "            else:\n",
    "                flat_dict.append({new_key: v})      \n",
    "        return flat_dict\n",
    "        \n",
    "\n",
    "    def transform(self, X):\n",
    "        # transform the data\n",
    "        if type(X)==dict:\n",
    "            # for json format, flattern the dictionary for attributes\n",
    "            self.flat_X = {k:v for d in self.flattern(X[self.key]) for k,v in d.items()}\n",
    "        else:\n",
    "            # for pandas (used for training), build a list of dictionaries\n",
    "            self.flat_X=X[self.key].map(lambda x: {k:v for d in self.flattern(x) for k,v in d.items()}).tolist()\n",
    "\n",
    "        return self.flat_X # transformation\n",
    "    \n",
    "\n",
    "att_model = Pipeline([('trans', AttributeTransformer('attributes')),\n",
    "                      ('vect', DictVectorizer()),\n",
    "                       ('est', lr_model())\n",
    "                      ])\n",
    "\n",
    "#fit and save model\n",
    "att_model.fit(df,y)\n",
    "dill.dump(att_model, open('att_model','w'))\n",
    "\n",
    "\n",
    "#Full model\n",
    "#A transformer that takes the estimators built above using pipeline,\n",
    "#and turns it into a transformer\n",
    "class com_Transformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator):\n",
    "        self.est = estimator\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.est.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.est.predict(X).reshape(-1,1)\n",
    "\n",
    "#feature union\n",
    "features = FeatureUnion(transformer_list = \n",
    "                        [('city', com_Transformer(city_model('city'))),\n",
    "                         ('latln', com_Transformer(latln_model)),\n",
    "                         ('cate', com_Transformer(cate_model)),\n",
    "                         ('att', com_Transformer(att_model))\n",
    "                        ])\n",
    "\n",
    "#pipeline the features with the linear estimator built above\n",
    "fullmodel = Pipeline([\n",
    "        ('featureunion', features), \n",
    "        ('est', lr_model())\n",
    "    ])\n",
    "\n",
    "#fit and save full model\n",
    "fullmodel.fit(df,y)\n",
    "dill.dump(fullmodel, open('full_model','w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
